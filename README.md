1.	Implemented fundamental concepts: vector spaces, bases, matrices, eigenvalues, and eigenvectors.
2.	Explored dense and sparse matrices, optimizing performance on CPUs and GPUs.
3.	Implemented vector rotations, orthogonalization methods, and QR factorization.
4.	Utilized interpolation, least squares, and numerical tools for data approximation.
5.	Analyzed iterative solutions for large-scale linear systems, considering convergence and memory.
6.	Applied numerical methods for eigenvalue computations, addressing stability.
7.	Studied Singular Value Decomposition (SVD) and its computational properties.
8.	Explored generalized and Moore-Penrose inverse matrices.
9.	Investigated dimensionality reduction techniques like PCA.
10.	Explored spectral clustering for data partitioning.

